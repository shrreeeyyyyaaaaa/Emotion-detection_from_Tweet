{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-zZ8Esdip1s",
        "outputId": "c8e5d76d-48a2-4d5a-c4d0-60b3c7fc0908"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ktrain\n",
            "  Downloading ktrain-0.38.0.tar.gz (25.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.3/25.3 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from ktrain) (1.2.2)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from ktrain) (3.7.1)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from ktrain) (1.5.3)\n",
            "Requirement already satisfied: fastprogress>=0.1.21 in /usr/local/lib/python3.10/dist-packages (from ktrain) (1.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ktrain) (2.31.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from ktrain) (1.3.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ktrain) (23.2)\n",
            "Collecting langdetect (from ktrain)\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (from ktrain) (0.42.1)\n",
            "Collecting cchardet (from ktrain)\n",
            "  Downloading cchardet-2.1.7.tar.gz (653 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m653.6/653.6 kB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from ktrain) (5.2.0)\n",
            "Collecting syntok>1.3.3 (from ktrain)\n",
            "  Downloading syntok-1.4.4-py3-none-any.whl (24 kB)\n",
            "Collecting tika (from ktrain)\n",
            "  Downloading tika-2.6.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting transformers>=4.17.0 (from ktrain)\n",
            "  Downloading transformers-4.34.1-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m104.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece (from ktrain)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m77.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras_bert>=0.86.0 (from ktrain)\n",
            "  Downloading keras-bert-0.89.0.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting whoosh (from ktrain)\n",
            "  Downloading Whoosh-2.7.4-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.8/468.8 kB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras_bert>=0.86.0->ktrain) (1.23.5)\n",
            "Collecting keras-transformer==0.40.0 (from keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-transformer-0.40.0.tar.gz (9.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-pos-embd==0.13.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-pos-embd-0.13.0.tar.gz (5.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-multi-head==0.29.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-multi-head-0.29.0.tar.gz (13 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-layer-normalization==0.16.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-layer-normalization-0.16.0.tar.gz (3.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-position-wise-feed-forward==0.8.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-position-wise-feed-forward-0.8.0.tar.gz (4.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-embed-sim==0.10.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-embed-sim-0.10.0.tar.gz (3.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-self-attention==0.51.0 (from keras-multi-head==0.29.0->keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-self-attention-0.51.0.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->ktrain) (2023.3.post1)\n",
            "Requirement already satisfied: regex>2016 in /usr/local/lib/python3.10/dist-packages (from syntok>1.3.3->ktrain) (2023.6.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers>=4.17.0->ktrain) (3.12.4)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers>=4.17.0->ktrain)\n",
            "  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.17.0->ktrain) (6.0.1)\n",
            "Collecting tokenizers<0.15,>=0.14 (from transformers>=4.17.0->ktrain)\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m108.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers>=4.17.0->ktrain)\n",
            "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.17.0->ktrain) (4.66.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect->ktrain) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ktrain) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ktrain) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ktrain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ktrain) (2023.7.22)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->ktrain) (1.11.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->ktrain) (3.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tika->ktrain) (67.7.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers>=4.17.0->ktrain) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers>=4.17.0->ktrain) (4.5.0)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers>=4.17.0->ktrain)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: ktrain, keras_bert, keras-transformer, keras-embed-sim, keras-layer-normalization, keras-multi-head, keras-pos-embd, keras-position-wise-feed-forward, keras-self-attention, cchardet, langdetect, tika\n",
            "  Building wheel for ktrain (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ktrain: filename=ktrain-0.38.0-py3-none-any.whl size=25319962 sha256=490f46235f4bba8e483b470253c24701434bc7e53c9cc4a399d88cbad6e37d11\n",
            "  Stored in directory: /root/.cache/pip/wheels/10/76/6b/5799f396ca78a8c38c7c6439a192ca88538a97cfb970946da5\n",
            "  Building wheel for keras_bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras_bert: filename=keras_bert-0.89.0-py3-none-any.whl size=33499 sha256=c5b9fd40873db4f9240898d9c4b1fdd9ca7e1876581cb393015ea3f9e4f9f2df\n",
            "  Stored in directory: /root/.cache/pip/wheels/89/0c/04/646b6fdf6375911b42c8d540a8a3fda8d5d77634e5dcbe7b26\n",
            "  Building wheel for keras-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-transformer: filename=keras_transformer-0.40.0-py3-none-any.whl size=12285 sha256=56a52d0d576621c3de1fa26f2453b1ca048cd6672d0e5949013509caa22dd64a\n",
            "  Stored in directory: /root/.cache/pip/wheels/f2/cb/22/75a0ad376129177f7c95c0d91331a18f5368fd657f4035ba7c\n",
            "  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.10.0-py3-none-any.whl size=3945 sha256=681e5d0caaee6ef38f4817cae8385d8a1551eb38a16949c3c41bdbd4b95f1fb6\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/32/c7/fd35d0d1b840a6c7cbd4343f808d10d0f7b87d271a4dbe796f\n",
            "  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.16.0-py3-none-any.whl size=4654 sha256=7f22d6d91ec8427741addf9df9e0d8534e376a10b7d1a8fffc810413a78f4d76\n",
            "  Stored in directory: /root/.cache/pip/wheels/ed/3a/4b/21db23c0cc56c4b219616e181f258eb7c57d36cc5d056fae9a\n",
            "  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-multi-head: filename=keras_multi_head-0.29.0-py3-none-any.whl size=14977 sha256=acf3cb241c655f9b4e715980c4e21831bd828e3882ca4a411b5906e765e7a847\n",
            "  Stored in directory: /root/.cache/pip/wheels/cb/23/4b/06d7ae21714f70fcc25b48f972cc8e5e7f4b6b764a038b509d\n",
            "  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.13.0-py3-none-any.whl size=6945 sha256=25836c3049ce39b4e1bd378639c2c5bf3d91ebe135d89901237d02595b114fca\n",
            "  Stored in directory: /root/.cache/pip/wheels/78/07/1b/b1ca47b6ac338554b75c8f52c54e6a2bfbe1b07d79579979a4\n",
            "  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.8.0-py3-none-any.whl size=4969 sha256=d4fda211fc4aedd703c3a0febccfadaf9fdc843fc9df5e35b161240a0859f17b\n",
            "  Stored in directory: /root/.cache/pip/wheels/c1/6a/04/d1706a53b23b2cb5f9a0a76269bf87925daa1bca09eac01b21\n",
            "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-self-attention: filename=keras_self_attention-0.51.0-py3-none-any.whl size=18895 sha256=270dd0ba9a93b5e4ed1696a9799f171c4a9f6b7772f2dac42e82e2f9cf564ba4\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/f7/24/607b483144fb9c47b4ba2c5fba6b68e54aeee2d5bf6c05302e\n",
            "  Building wheel for cchardet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cchardet: filename=cchardet-2.1.7-cp310-cp310-linux_x86_64.whl size=289195 sha256=d476a535308713d8b9fd422f9ed71a68eee5ae6efac74cd56bf8f64e8f649cd1\n",
            "  Stored in directory: /root/.cache/pip/wheels/ee/e0/ab/e01326f15c59438d080b1496dbab8091e952ec72f35e3c437e\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993224 sha256=c9a09b5ba2d91b89c57ba247dbb6e789a94f99e1fc60ea8b2c08b6cac37704ca\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "  Building wheel for tika (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tika: filename=tika-2.6.0-py3-none-any.whl size=32621 sha256=5974da328dcd6f475bd7158dcf5513bfdb0514d575e4c996a06091a5ab03ff71\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/71/c7/b757709531121b1700cffda5b6b0d4aad095fb507ec84316d0\n",
            "Successfully built ktrain keras_bert keras-transformer keras-embed-sim keras-layer-normalization keras-multi-head keras-pos-embd keras-position-wise-feed-forward keras-self-attention cchardet langdetect tika\n",
            "Installing collected packages: whoosh, sentencepiece, cchardet, syntok, safetensors, langdetect, keras-self-attention, keras-position-wise-feed-forward, keras-pos-embd, keras-layer-normalization, keras-embed-sim, tika, keras-multi-head, huggingface-hub, tokenizers, keras-transformer, transformers, keras_bert, ktrain\n",
            "Successfully installed cchardet-2.1.7 huggingface-hub-0.17.3 keras-embed-sim-0.10.0 keras-layer-normalization-0.16.0 keras-multi-head-0.29.0 keras-pos-embd-0.13.0 keras-position-wise-feed-forward-0.8.0 keras-self-attention-0.51.0 keras-transformer-0.40.0 keras_bert-0.89.0 ktrain-0.38.0 langdetect-1.0.9 safetensors-0.4.0 sentencepiece-0.1.99 syntok-1.4.4 tika-2.6.0 tokenizers-0.14.1 transformers-4.34.1 whoosh-2.7.4\n"
          ]
        }
      ],
      "source": [
        "!pip3 install ktrain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NawlDtYDol0e"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import ktrain\n",
        "from ktrain import text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwYkdeAHpv_K",
        "outputId": "474e0cdd-c74b-4b76-bf4b-3bf75ea1d4b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df= pd.read_csv(\"/content/tweet_and_emotion.csv\")"
      ],
      "metadata": {
        "id": "4Vim8D9k1mYS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPLWe-kS11x2",
        "outputId": "6682133d-03dd-4823-f596-71490429408f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10624, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.emotions.value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alZfirfB2i1i",
        "outputId": "b6f87cdf-a953-4fe0-e44f-09e3012e8d71"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fear       2252\n",
            "neutral    2238\n",
            "sadness    2198\n",
            "joy        2125\n",
            "anger      1811\n",
            "Name: emotions, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "yOrTgca_qXIO"
      },
      "outputs": [],
      "source": [
        "data_set = df['tweet']\n",
        "target= df['emotions']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "TkbChT8GqZ_v"
      },
      "outputs": [],
      "source": [
        "class_names = [\"fear\",\"neutral\",\"sadness\",\"joy\",\"anger\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Fx-Jw5LLqzMh"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test=train_test_split(data_set, target , test_size=0.2 ,random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "coB68QHlrV_K"
      },
      "outputs": [],
      "source": [
        "x_train = x_train.tolist()\n",
        "x_test = x_test.tolist()\n",
        "\n",
        "y_train = y_train.tolist()\n",
        "y_test = y_test.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "5lpGHJt_rYho"
      },
      "outputs": [],
      "source": [
        "encoding = {\n",
        "  \"fear\":0,\n",
        "  \"neutral\":1,\n",
        " \"sadness\":2,\n",
        "  \"joy\":3,\n",
        " \"anger\":4,\n",
        "}\n",
        "\n",
        "# Integer values for each class\n",
        "y_train = [encoding[x] for x in y_train]\n",
        "y_test = [encoding[x] for x in y_test]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "TQzArlVgrdZT",
        "outputId": "6a78f7ed-b179-4fda-c8ad-441b6f1e2ca1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading pretrained BERT model (uncased_L-12_H-768_A-12.zip)...\n",
            "[██████████████████████████████████████████████████]\n",
            "extracting pretrained BERT model...\n",
            "done.\n",
            "\n",
            "cleanup downloaded zip...\n",
            "done.\n",
            "\n",
            "preprocessing train...\n",
            "language: en\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "done."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is Multi-Label? False\n",
            "preprocessing test...\n",
            "language: en\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "done."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "task: text classification\n"
          ]
        }
      ],
      "source": [
        "(x_train,  y_train), (x_test, y_test), preproc = text.texts_from_array(x_train=x_train, y_train=y_train,\n",
        "                                                                       x_test=x_test, y_test=y_test,\n",
        "                                                                       class_names=class_names,\n",
        "                                                                       preprocess_mode='bert',\n",
        "                                                                       maxlen=350,\n",
        "                                                                       max_features=35000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuuSs5bZrlJv",
        "outputId": "2ef85ee3-eb8a-4bc7-da2c-56f79fe9b5e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is Multi-Label? False\n",
            "maxlen is 350\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/initializers/initializers.py:120: UserWarning: The initializer GlorotNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done.\n"
          ]
        }
      ],
      "source": [
        "model = text.text_classifier('bert', train_data=(x_train, y_train), preproc=preproc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1niUYXV8w6x4",
        "outputId": "0fe29e28-884d-499e-d1d5-017fa4d19765"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " Input-Token (InputLayer)    [(None, 350)]                0         []                            \n",
            "                                                                                                  \n",
            " Input-Segment (InputLayer)  [(None, 350)]                0         []                            \n",
            "                                                                                                  \n",
            " Embedding-Token (TokenEmbe  [(None, 350, 768),           2344089   ['Input-Token[0][0]']         \n",
            " dding)                       (30522, 768)]               6                                       \n",
            "                                                                                                  \n",
            " Embedding-Segment (Embeddi  (None, 350, 768)             1536      ['Input-Segment[0][0]']       \n",
            " ng)                                                                                              \n",
            "                                                                                                  \n",
            " Embedding-Token-Segment (A  (None, 350, 768)             0         ['Embedding-Token[0][0]',     \n",
            " dd)                                                                 'Embedding-Segment[0][0]']   \n",
            "                                                                                                  \n",
            " Embedding-Position (Positi  (None, 350, 768)             268800    ['Embedding-Token-Segment[0][0\n",
            " onEmbedding)                                                       ]']                           \n",
            "                                                                                                  \n",
            " Embedding-Dropout (Dropout  (None, 350, 768)             0         ['Embedding-Position[0][0]']  \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " Embedding-Norm (LayerNorma  (None, 350, 768)             1536      ['Embedding-Dropout[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " Encoder-1-MultiHeadSelfAtt  (None, 350, 768)             2362368   ['Embedding-Norm[0][0]']      \n",
            " ention (MultiHeadAttention                                                                       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " Encoder-1-MultiHeadSelfAtt  (None, 350, 768)             0         ['Encoder-1-MultiHeadSelfAtten\n",
            " ention-Dropout (Dropout)                                           tion[0][0]']                  \n",
            "                                                                                                  \n",
            " Encoder-1-MultiHeadSelfAtt  (None, 350, 768)             0         ['Embedding-Norm[0][0]',      \n",
            " ention-Add (Add)                                                    'Encoder-1-MultiHeadSelfAtten\n",
            "                                                                    tion-Dropout[0][0]']          \n",
            "                                                                                                  \n",
            " Encoder-1-MultiHeadSelfAtt  (None, 350, 768)             1536      ['Encoder-1-MultiHeadSelfAtten\n",
            " ention-Norm (LayerNormaliz                                         tion-Add[0][0]']              \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " Encoder-1-FeedForward (Fee  (None, 350, 768)             4722432   ['Encoder-1-MultiHeadSelfAtten\n",
            " dForward)                                                          tion-Norm[0][0]']             \n",
            "                                                                                                  \n",
            " Encoder-1-FeedForward-Drop  (None, 350, 768)             0         ['Encoder-1-FeedForward[0][0]'\n",
            " out (Dropout)                                                      ]                             \n",
            "                                                                                                  \n",
            " Encoder-1-FeedForward-Add   (None, 350, 768)             0         ['Encoder-1-MultiHeadSelfAtten\n",
            " (Add)                                                              tion-Norm[0][0]',             \n",
            "                                                                     'Encoder-1-FeedForward-Dropou\n",
            "                                                                    t[0][0]']                     \n",
            "                                                                                                  \n",
            " Encoder-1-FeedForward-Norm  (None, 350, 768)             1536      ['Encoder-1-FeedForward-Add[0]\n",
            "  (LayerNormalization)                                              [0]']                         \n",
            "                                                                                                  \n",
            " Encoder-2-MultiHeadSelfAtt  (None, 350, 768)             2362368   ['Encoder-1-FeedForward-Norm[0\n",
            " ention (MultiHeadAttention                                         ][0]']                        \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " Encoder-2-MultiHeadSelfAtt  (None, 350, 768)             0         ['Encoder-2-MultiHeadSelfAtten\n",
            " ention-Dropout (Dropout)                                           tion[0][0]']                  \n",
            "                                                                                                  \n",
            " Encoder-2-MultiHeadSelfAtt  (None, 350, 768)             0         ['Encoder-1-FeedForward-Norm[0\n",
            " ention-Add (Add)                                                   ][0]',                        \n",
            "                                                                     'Encoder-2-MultiHeadSelfAtten\n",
            "                                                                    tion-Dropout[0][0]']          \n",
            "                                                                                                  \n",
            " Encoder-2-MultiHeadSelfAtt  (None, 350, 768)             1536      ['Encoder-2-MultiHeadSelfAtten\n",
            " ention-Norm (LayerNormaliz                                         tion-Add[0][0]']              \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " Encoder-2-FeedForward (Fee  (None, 350, 768)             4722432   ['Encoder-2-MultiHeadSelfAtten\n",
            " dForward)                                                          tion-Norm[0][0]']             \n",
            "                                                                                                  \n",
            " Encoder-2-FeedForward-Drop  (None, 350, 768)             0         ['Encoder-2-FeedForward[0][0]'\n",
            " out (Dropout)                                                      ]                             \n",
            "                                                                                                  \n",
            " Encoder-2-FeedForward-Add   (None, 350, 768)             0         ['Encoder-2-MultiHeadSelfAtten\n",
            " (Add)                                                              tion-Norm[0][0]',             \n",
            "                                                                     'Encoder-2-FeedForward-Dropou\n",
            "                                                                    t[0][0]']                     \n",
            "                                                                                                  \n",
            " Encoder-2-FeedForward-Norm  (None, 350, 768)             1536      ['Encoder-2-FeedForward-Add[0]\n",
            "  (LayerNormalization)                                              [0]']                         \n",
            "                                                                                                  \n",
            " Encoder-3-MultiHeadSelfAtt  (None, 350, 768)             2362368   ['Encoder-2-FeedForward-Norm[0\n",
            " ention (MultiHeadAttention                                         ][0]']                        \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " Encoder-3-MultiHeadSelfAtt  (None, 350, 768)             0         ['Encoder-3-MultiHeadSelfAtten\n",
            " ention-Dropout (Dropout)                                           tion[0][0]']                  \n",
            "                                                                                                  \n",
            " Encoder-3-MultiHeadSelfAtt  (None, 350, 768)             0         ['Encoder-2-FeedForward-Norm[0\n",
            " ention-Add (Add)                                                   ][0]',                        \n",
            "                                                                     'Encoder-3-MultiHeadSelfAtten\n",
            "                                                                    tion-Dropout[0][0]']          \n",
            "                                                                                                  \n",
            " Encoder-3-MultiHeadSelfAtt  (None, 350, 768)             1536      ['Encoder-3-MultiHeadSelfAtten\n",
            " ention-Norm (LayerNormaliz                                         tion-Add[0][0]']              \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " Encoder-3-FeedForward (Fee  (None, 350, 768)             4722432   ['Encoder-3-MultiHeadSelfAtten\n",
            " dForward)                                                          tion-Norm[0][0]']             \n",
            "                                                                                                  \n",
            " Encoder-3-FeedForward-Drop  (None, 350, 768)             0         ['Encoder-3-FeedForward[0][0]'\n",
            " out (Dropout)                                                      ]                             \n",
            "                                                                                                  \n",
            " Encoder-3-FeedForward-Add   (None, 350, 768)             0         ['Encoder-3-MultiHeadSelfAtten\n",
            " (Add)                                                              tion-Norm[0][0]',             \n",
            "                                                                     'Encoder-3-FeedForward-Dropou\n",
            "                                                                    t[0][0]']                     \n",
            "                                                                                                  \n",
            " Encoder-3-FeedForward-Norm  (None, 350, 768)             1536      ['Encoder-3-FeedForward-Add[0]\n",
            "  (LayerNormalization)                                              [0]']                         \n",
            "                                                                                                  \n",
            " Encoder-4-MultiHeadSelfAtt  (None, 350, 768)             2362368   ['Encoder-3-FeedForward-Norm[0\n",
            " ention (MultiHeadAttention                                         ][0]']                        \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " Encoder-4-MultiHeadSelfAtt  (None, 350, 768)             0         ['Encoder-4-MultiHeadSelfAtten\n",
            " ention-Dropout (Dropout)                                           tion[0][0]']                  \n",
            "                                                                                                  \n",
            " Encoder-4-MultiHeadSelfAtt  (None, 350, 768)             0         ['Encoder-3-FeedForward-Norm[0\n",
            " ention-Add (Add)                                                   ][0]',                        \n",
            "                                                                     'Encoder-4-MultiHeadSelfAtten\n",
            "                                                                    tion-Dropout[0][0]']          \n",
            "                                                                                                  \n",
            " Encoder-4-MultiHeadSelfAtt  (None, 350, 768)             1536      ['Encoder-4-MultiHeadSelfAtten\n",
            " ention-Norm (LayerNormaliz                                         tion-Add[0][0]']              \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " Encoder-4-FeedForward (Fee  (None, 350, 768)             4722432   ['Encoder-4-MultiHeadSelfAtten\n",
            " dForward)                                                          tion-Norm[0][0]']             \n",
            "                                                                                                  \n",
            " Encoder-4-FeedForward-Drop  (None, 350, 768)             0         ['Encoder-4-FeedForward[0][0]'\n",
            " out (Dropout)                                                      ]                             \n",
            "                                                                                                  \n",
            " Encoder-4-FeedForward-Add   (None, 350, 768)             0         ['Encoder-4-MultiHeadSelfAtten\n",
            " (Add)                                                              tion-Norm[0][0]',             \n",
            "                                                                     'Encoder-4-FeedForward-Dropou\n",
            "                                                                    t[0][0]']                     \n",
            "                                                                                                  \n",
            " Encoder-4-FeedForward-Norm  (None, 350, 768)             1536      ['Encoder-4-FeedForward-Add[0]\n",
            "  (LayerNormalization)                                              [0]']                         \n",
            "                                                                                                  \n",
            " Encoder-5-MultiHeadSelfAtt  (None, 350, 768)             2362368   ['Encoder-4-FeedForward-Norm[0\n",
            " ention (MultiHeadAttention                                         ][0]']                        \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " Encoder-5-MultiHeadSelfAtt  (None, 350, 768)             0         ['Encoder-5-MultiHeadSelfAtten\n",
            " ention-Dropout (Dropout)                                           tion[0][0]']                  \n",
            "                                                                                                  \n",
            " Encoder-5-MultiHeadSelfAtt  (None, 350, 768)             0         ['Encoder-4-FeedForward-Norm[0\n",
            " ention-Add (Add)                                                   ][0]',                        \n",
            "                                                                     'Encoder-5-MultiHeadSelfAtten\n",
            "                                                                    tion-Dropout[0][0]']          \n",
            "                                                                                                  \n",
            " Encoder-5-MultiHeadSelfAtt  (None, 350, 768)             1536      ['Encoder-5-MultiHeadSelfAtten\n",
            " ention-Norm (LayerNormaliz                                         tion-Add[0][0]']              \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " Encoder-5-FeedForward (Fee  (None, 350, 768)             4722432   ['Encoder-5-MultiHeadSelfAtten\n",
            " dForward)                                                          tion-Norm[0][0]']             \n",
            "                                                                                                  \n",
            " Encoder-5-FeedForward-Drop  (None, 350, 768)             0         ['Encoder-5-FeedForward[0][0]'\n",
            " out (Dropout)                                                      ]                             \n",
            "                                                                                                  \n",
            " Encoder-5-FeedForward-Add   (None, 350, 768)             0         ['Encoder-5-MultiHeadSelfAtten\n",
            " (Add)                                                              tion-Norm[0][0]',             \n",
            "                                                                     'Encoder-5-FeedForward-Dropou\n",
            "                                                                    t[0][0]']                     \n",
            "                                                                                                  \n",
            " Encoder-5-FeedForward-Norm  (None, 350, 768)             1536      ['Encoder-5-FeedForward-Add[0]\n",
            "  (LayerNormalization)                                              [0]']                         \n",
            "                                                                                                  \n",
            " Encoder-6-MultiHeadSelfAtt  (None, 350, 768)             2362368   ['Encoder-5-FeedForward-Norm[0\n",
            " ention (MultiHeadAttention                                         ][0]']                        \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " Encoder-6-MultiHeadSelfAtt  (None, 350, 768)             0         ['Encoder-6-MultiHeadSelfAtten\n",
            " ention-Dropout (Dropout)                                           tion[0][0]']                  \n",
            "                                                                                                  \n",
            " Encoder-6-MultiHeadSelfAtt  (None, 350, 768)             0         ['Encoder-5-FeedForward-Norm[0\n",
            " ention-Add (Add)                                                   ][0]',                        \n",
            "                                                                     'Encoder-6-MultiHeadSelfAtten\n",
            "                                                                    tion-Dropout[0][0]']          \n",
            "                                                                                                  \n",
            " Encoder-6-MultiHeadSelfAtt  (None, 350, 768)             1536      ['Encoder-6-MultiHeadSelfAtten\n",
            " ention-Norm (LayerNormaliz                                         tion-Add[0][0]']              \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " Encoder-6-FeedForward (Fee  (None, 350, 768)             4722432   ['Encoder-6-MultiHeadSelfAtten\n",
            " dForward)                                                          tion-Norm[0][0]']             \n",
            "                                                                                                  \n",
            " Encoder-6-FeedForward-Drop  (None, 350, 768)             0         ['Encoder-6-FeedForward[0][0]'\n",
            " out (Dropout)                                                      ]                             \n",
            "                                                                                                  \n",
            " Encoder-6-FeedForward-Add   (None, 350, 768)             0         ['Encoder-6-MultiHeadSelfAtten\n",
            " (Add)                                                              tion-Norm[0][0]',             \n",
            "                                                                     'Encoder-6-FeedForward-Dropou\n",
            "                                                                    t[0][0]']                     \n",
            "                                                                                                  \n",
            " Encoder-6-FeedForward-Norm  (None, 350, 768)             1536      ['Encoder-6-FeedForward-Add[0]\n",
            "  (LayerNormalization)                                              [0]']                         \n",
            "                                                                                                  \n",
            " Encoder-7-MultiHeadSelfAtt  (None, 350, 768)             2362368   ['Encoder-6-FeedForward-Norm[0\n",
            " ention (MultiHeadAttention                                         ][0]']                        \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " Encoder-7-MultiHeadSelfAtt  (None, 350, 768)             0         ['Encoder-7-MultiHeadSelfAtten\n",
            " ention-Dropout (Dropout)                                           tion[0][0]']                  \n",
            "                                                                                                  \n",
            " Encoder-7-MultiHeadSelfAtt  (None, 350, 768)             0         ['Encoder-6-FeedForward-Norm[0\n",
            " ention-Add (Add)                                                   ][0]',                        \n",
            "                                                                     'Encoder-7-MultiHeadSelfAtten\n",
            "                                                                    tion-Dropout[0][0]']          \n",
            "                                                                                                  \n",
            " Encoder-7-MultiHeadSelfAtt  (None, 350, 768)             1536      ['Encoder-7-MultiHeadSelfAtten\n",
            " ention-Norm (LayerNormaliz                                         tion-Add[0][0]']              \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " Encoder-7-FeedForward (Fee  (None, 350, 768)             4722432   ['Encoder-7-MultiHeadSelfAtten\n",
            " dForward)                                                          tion-Norm[0][0]']             \n",
            "                                                                                                  \n",
            " Encoder-7-FeedForward-Drop  (None, 350, 768)             0         ['Encoder-7-FeedForward[0][0]'\n",
            " out (Dropout)                                                      ]                             \n",
            "                                                                                                  \n",
            " Encoder-7-FeedForward-Add   (None, 350, 768)             0         ['Encoder-7-MultiHeadSelfAtten\n",
            " (Add)                                                              tion-Norm[0][0]',             \n",
            "                                                                     'Encoder-7-FeedForward-Dropou\n",
            "                                                                    t[0][0]']                     \n",
            "                                                                                                  \n",
            " Encoder-7-FeedForward-Norm  (None, 350, 768)             1536      ['Encoder-7-FeedForward-Add[0]\n",
            "  (LayerNormalization)                                              [0]']                         \n",
            "                                                                                                  \n",
            " Encoder-8-MultiHeadSelfAtt  (None, 350, 768)             2362368   ['Encoder-7-FeedForward-Norm[0\n",
            " ention (MultiHeadAttention                                         ][0]']                        \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " Encoder-8-MultiHeadSelfAtt  (None, 350, 768)             0         ['Encoder-8-MultiHeadSelfAtten\n",
            " ention-Dropout (Dropout)                                           tion[0][0]']                  \n",
            "                                                                                                  \n",
            " Encoder-8-MultiHeadSelfAtt  (None, 350, 768)             0         ['Encoder-7-FeedForward-Norm[0\n",
            " ention-Add (Add)                                                   ][0]',                        \n",
            "                                                                     'Encoder-8-MultiHeadSelfAtten\n",
            "                                                                    tion-Dropout[0][0]']          \n",
            "                                                                                                  \n",
            " Encoder-8-MultiHeadSelfAtt  (None, 350, 768)             1536      ['Encoder-8-MultiHeadSelfAtten\n",
            " ention-Norm (LayerNormaliz                                         tion-Add[0][0]']              \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " Encoder-8-FeedForward (Fee  (None, 350, 768)             4722432   ['Encoder-8-MultiHeadSelfAtten\n",
            " dForward)                                                          tion-Norm[0][0]']             \n",
            "                                                                                                  \n",
            " Encoder-8-FeedForward-Drop  (None, 350, 768)             0         ['Encoder-8-FeedForward[0][0]'\n",
            " out (Dropout)                                                      ]                             \n",
            "                                                                                                  \n",
            " Encoder-8-FeedForward-Add   (None, 350, 768)             0         ['Encoder-8-MultiHeadSelfAtten\n",
            " (Add)                                                              tion-Norm[0][0]',             \n",
            "                                                                     'Encoder-8-FeedForward-Dropou\n",
            "                                                                    t[0][0]']                     \n",
            "                                                                                                  \n",
            " Encoder-8-FeedForward-Norm  (None, 350, 768)             1536      ['Encoder-8-FeedForward-Add[0]\n",
            "  (LayerNormalization)                                              [0]']                         \n",
            "                                                                                                  \n",
            " Encoder-9-MultiHeadSelfAtt  (None, 350, 768)             2362368   ['Encoder-8-FeedForward-Norm[0\n",
            " ention (MultiHeadAttention                                         ][0]']                        \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " Encoder-9-MultiHeadSelfAtt  (None, 350, 768)             0         ['Encoder-9-MultiHeadSelfAtten\n",
            " ention-Dropout (Dropout)                                           tion[0][0]']                  \n",
            "                                                                                                  \n",
            " Encoder-9-MultiHeadSelfAtt  (None, 350, 768)             0         ['Encoder-8-FeedForward-Norm[0\n",
            " ention-Add (Add)                                                   ][0]',                        \n",
            "                                                                     'Encoder-9-MultiHeadSelfAtten\n",
            "                                                                    tion-Dropout[0][0]']          \n",
            "                                                                                                  \n",
            " Encoder-9-MultiHeadSelfAtt  (None, 350, 768)             1536      ['Encoder-9-MultiHeadSelfAtten\n",
            " ention-Norm (LayerNormaliz                                         tion-Add[0][0]']              \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " Encoder-9-FeedForward (Fee  (None, 350, 768)             4722432   ['Encoder-9-MultiHeadSelfAtten\n",
            " dForward)                                                          tion-Norm[0][0]']             \n",
            "                                                                                                  \n",
            " Encoder-9-FeedForward-Drop  (None, 350, 768)             0         ['Encoder-9-FeedForward[0][0]'\n",
            " out (Dropout)                                                      ]                             \n",
            "                                                                                                  \n",
            " Encoder-9-FeedForward-Add   (None, 350, 768)             0         ['Encoder-9-MultiHeadSelfAtten\n",
            " (Add)                                                              tion-Norm[0][0]',             \n",
            "                                                                     'Encoder-9-FeedForward-Dropou\n",
            "                                                                    t[0][0]']                     \n",
            "                                                                                                  \n",
            " Encoder-9-FeedForward-Norm  (None, 350, 768)             1536      ['Encoder-9-FeedForward-Add[0]\n",
            "  (LayerNormalization)                                              [0]']                         \n",
            "                                                                                                  \n",
            " Encoder-10-MultiHeadSelfAt  (None, 350, 768)             2362368   ['Encoder-9-FeedForward-Norm[0\n",
            " tention (MultiHeadAttentio                                         ][0]']                        \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " Encoder-10-MultiHeadSelfAt  (None, 350, 768)             0         ['Encoder-10-MultiHeadSelfAtte\n",
            " tention-Dropout (Dropout)                                          ntion[0][0]']                 \n",
            "                                                                                                  \n",
            " Encoder-10-MultiHeadSelfAt  (None, 350, 768)             0         ['Encoder-9-FeedForward-Norm[0\n",
            " tention-Add (Add)                                                  ][0]',                        \n",
            "                                                                     'Encoder-10-MultiHeadSelfAtte\n",
            "                                                                    ntion-Dropout[0][0]']         \n",
            "                                                                                                  \n",
            " Encoder-10-MultiHeadSelfAt  (None, 350, 768)             1536      ['Encoder-10-MultiHeadSelfAtte\n",
            " tention-Norm (LayerNormali                                         ntion-Add[0][0]']             \n",
            " zation)                                                                                          \n",
            "                                                                                                  \n",
            " Encoder-10-FeedForward (Fe  (None, 350, 768)             4722432   ['Encoder-10-MultiHeadSelfAtte\n",
            " edForward)                                                         ntion-Norm[0][0]']            \n",
            "                                                                                                  \n",
            " Encoder-10-FeedForward-Dro  (None, 350, 768)             0         ['Encoder-10-FeedForward[0][0]\n",
            " pout (Dropout)                                                     ']                            \n",
            "                                                                                                  \n",
            " Encoder-10-FeedForward-Add  (None, 350, 768)             0         ['Encoder-10-MultiHeadSelfAtte\n",
            "  (Add)                                                             ntion-Norm[0][0]',            \n",
            "                                                                     'Encoder-10-FeedForward-Dropo\n",
            "                                                                    ut[0][0]']                    \n",
            "                                                                                                  \n",
            " Encoder-10-FeedForward-Nor  (None, 350, 768)             1536      ['Encoder-10-FeedForward-Add[0\n",
            " m (LayerNormalization)                                             ][0]']                        \n",
            "                                                                                                  \n",
            " Encoder-11-MultiHeadSelfAt  (None, 350, 768)             2362368   ['Encoder-10-FeedForward-Norm[\n",
            " tention (MultiHeadAttentio                                         0][0]']                       \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " Encoder-11-MultiHeadSelfAt  (None, 350, 768)             0         ['Encoder-11-MultiHeadSelfAtte\n",
            " tention-Dropout (Dropout)                                          ntion[0][0]']                 \n",
            "                                                                                                  \n",
            " Encoder-11-MultiHeadSelfAt  (None, 350, 768)             0         ['Encoder-10-FeedForward-Norm[\n",
            " tention-Add (Add)                                                  0][0]',                       \n",
            "                                                                     'Encoder-11-MultiHeadSelfAtte\n",
            "                                                                    ntion-Dropout[0][0]']         \n",
            "                                                                                                  \n",
            " Encoder-11-MultiHeadSelfAt  (None, 350, 768)             1536      ['Encoder-11-MultiHeadSelfAtte\n",
            " tention-Norm (LayerNormali                                         ntion-Add[0][0]']             \n",
            " zation)                                                                                          \n",
            "                                                                                                  \n",
            " Encoder-11-FeedForward (Fe  (None, 350, 768)             4722432   ['Encoder-11-MultiHeadSelfAtte\n",
            " edForward)                                                         ntion-Norm[0][0]']            \n",
            "                                                                                                  \n",
            " Encoder-11-FeedForward-Dro  (None, 350, 768)             0         ['Encoder-11-FeedForward[0][0]\n",
            " pout (Dropout)                                                     ']                            \n",
            "                                                                                                  \n",
            " Encoder-11-FeedForward-Add  (None, 350, 768)             0         ['Encoder-11-MultiHeadSelfAtte\n",
            "  (Add)                                                             ntion-Norm[0][0]',            \n",
            "                                                                     'Encoder-11-FeedForward-Dropo\n",
            "                                                                    ut[0][0]']                    \n",
            "                                                                                                  \n",
            " Encoder-11-FeedForward-Nor  (None, 350, 768)             1536      ['Encoder-11-FeedForward-Add[0\n",
            " m (LayerNormalization)                                             ][0]']                        \n",
            "                                                                                                  \n",
            " Encoder-12-MultiHeadSelfAt  (None, 350, 768)             2362368   ['Encoder-11-FeedForward-Norm[\n",
            " tention (MultiHeadAttentio                                         0][0]']                       \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " Encoder-12-MultiHeadSelfAt  (None, 350, 768)             0         ['Encoder-12-MultiHeadSelfAtte\n",
            " tention-Dropout (Dropout)                                          ntion[0][0]']                 \n",
            "                                                                                                  \n",
            " Encoder-12-MultiHeadSelfAt  (None, 350, 768)             0         ['Encoder-11-FeedForward-Norm[\n",
            " tention-Add (Add)                                                  0][0]',                       \n",
            "                                                                     'Encoder-12-MultiHeadSelfAtte\n",
            "                                                                    ntion-Dropout[0][0]']         \n",
            "                                                                                                  \n",
            " Encoder-12-MultiHeadSelfAt  (None, 350, 768)             1536      ['Encoder-12-MultiHeadSelfAtte\n",
            " tention-Norm (LayerNormali                                         ntion-Add[0][0]']             \n",
            " zation)                                                                                          \n",
            "                                                                                                  \n",
            " Encoder-12-FeedForward (Fe  (None, 350, 768)             4722432   ['Encoder-12-MultiHeadSelfAtte\n",
            " edForward)                                                         ntion-Norm[0][0]']            \n",
            "                                                                                                  \n",
            " Encoder-12-FeedForward-Dro  (None, 350, 768)             0         ['Encoder-12-FeedForward[0][0]\n",
            " pout (Dropout)                                                     ']                            \n",
            "                                                                                                  \n",
            " Encoder-12-FeedForward-Add  (None, 350, 768)             0         ['Encoder-12-MultiHeadSelfAtte\n",
            "  (Add)                                                             ntion-Norm[0][0]',            \n",
            "                                                                     'Encoder-12-FeedForward-Dropo\n",
            "                                                                    ut[0][0]']                    \n",
            "                                                                                                  \n",
            " Encoder-12-FeedForward-Nor  (None, 350, 768)             1536      ['Encoder-12-FeedForward-Add[0\n",
            " m (LayerNormalization)                                             ][0]']                        \n",
            "                                                                                                  \n",
            " Extract (Extract)           (None, 768)                  0         ['Encoder-12-FeedForward-Norm[\n",
            "                                                                    0][0]']                       \n",
            "                                                                                                  \n",
            " NSP-Dense (Dense)           (None, 768)                  590592    ['Extract[0][0]']             \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 5)                    3845      ['NSP-Dense[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109361669 (417.18 MB)\n",
            "Trainable params: 109361669 (417.18 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "zc4NneNsrqlD"
      },
      "outputs": [],
      "source": [
        "learner = ktrain.get_learner(model, train_data=(x_train, y_train),\n",
        "                             val_data=(x_test, y_test),\n",
        "                             batch_size=6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaaxy4L4r-wz",
        "outputId": "1aca8dc8-7639-49da-f9ab-5a41da68f2e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "simulating training for different learning rates... this may take a few moments...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1024\n",
            "1417/1417 [==============================] - 767s 521ms/step - loss: 6.3893 - accuracy: 0.2866\n",
            "Epoch 2/1024\n",
            "1417/1417 [==============================] - 1s 3us/step - loss: 86.6103 - accuracy: 0.1667\n",
            "\n",
            "\n",
            "done.\n",
            "Please invoke the Learner.lr_plot() method to visually inspect the loss plot to help identify the maximal learning rate associated with falling loss.\n"
          ]
        }
      ],
      "source": [
        "learner.lr_find()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "RgA8gJHrr_0v",
        "outputId": "62942cc4-26d8-4e96-98cc-a4c0c6557ac2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "learner.lr_plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRETXT_ZrwN5",
        "outputId": "a3dcd0ba-24e4-4b89-c572-9866f350a789"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "begin training using onecycle policy with max lr of 1e-05...\n",
            "Epoch 1/3\n",
            "1417/1417 [==============================] - 855s 588ms/step - loss: 1.3068 - accuracy: 0.4415 - val_loss: 0.7805 - val_accuracy: 0.7172\n",
            "Epoch 2/3\n",
            "1417/1417 [==============================] - 829s 585ms/step - loss: 0.6582 - accuracy: 0.7628 - val_loss: 0.5979 - val_accuracy: 0.7859\n",
            "Epoch 3/3\n",
            "1417/1417 [==============================] - 829s 585ms/step - loss: 0.4077 - accuracy: 0.8541 - val_loss: 0.6120 - val_accuracy: 0.7779\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x782a3cebea10>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "learner.fit_onecycle(1e-5, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1icWjKA_Th6V",
        "outputId": "1c130871-4e6d-4ba5-cc48-610e18bd52d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "67/67 [==============================] - 64s 899ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fear       0.81      0.86      0.83       436\n",
            "     neutral       0.69      0.77      0.73       451\n",
            "     sadness       0.74      0.69      0.72       436\n",
            "         joy       0.85      0.77      0.81       439\n",
            "       anger       0.83      0.79      0.81       363\n",
            "\n",
            "    accuracy                           0.78      2125\n",
            "   macro avg       0.78      0.78      0.78      2125\n",
            "weighted avg       0.78      0.78      0.78      2125\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[376,  13,  22,   9,  16],\n",
              "       [ 11, 348,  51,  33,   8],\n",
              "       [ 33,  59, 303,  13,  28],\n",
              "       [ 18,  67,   9, 339,   6],\n",
              "       [ 27,  19,  26,   4, 287]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "learner.validate(val_data=(x_test, y_test), class_names=class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "PvrtV5E8aFQK"
      },
      "outputs": [],
      "source": [
        "predictor = ktrain.get_predictor(learner.model, preproc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "HmDs41h-VWTs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0425e86a-bf7c-44c5-fcbf-5a69056813cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "predictor.save(\"models/tweet_emotion_model\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}